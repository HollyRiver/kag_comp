{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 샘플의 베스트\n",
    "\n",
    "\"reindeer mistletoe elf gingerbread family advent scrooge chimney fireplace ornament\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc ## for memory\n",
    "import os\n",
    "import copy\n",
    "from math import exp\n",
    "from collections import Counter\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "from kaggle_evaluate import PerplexityCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6663cba9b5c411ca5dd7988587ea7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluatr = PerplexityCalculator(\"google/gemma-2-9b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` beam size : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle rooped\n",
      "cycle rooped\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m         word_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(beam \u001b[38;5;241m+\u001b[39m [t]))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(word_list[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m40\u001b[39m :\n\u001b[0;32m---> 25\u001b[0m     perplexities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mevaluatr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_perplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m     28\u001b[0m     perplexities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(evaluatr\u001b[38;5;241m.\u001b[39mget_perplexity(word_list, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m))\n",
      "File \u001b[0;32m~/kag_comp/Santa Metric/kaggle_evaluate.py:259\u001b[0m, in \u001b[0;36mPerplexityCalculator.get_perplexity\u001b[0;34m(self, input_texts, batch_size)\u001b[0m\n\u001b[1;32m    256\u001b[0m         valid_length \u001b[38;5;241m=\u001b[39m (shift_labels \u001b[38;5;241m!=\u001b[39m PAD_TOKEN_LABEL_ID)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    257\u001b[0m         loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(loss, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m valid_length\n\u001b[0;32m--> 259\u001b[0m         loss_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    262\u001b[0m ppl \u001b[38;5;241m=\u001b[39m [exp(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m loss_list]\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ppl[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single_input \u001b[38;5;28;01melse\u001b[39;00m ppl\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_tokens = df_sample.text.str.split().to_list()\n",
    "beam_size = [5, 10, 10, 15, 25, 50]\n",
    "best_word = []\n",
    "\n",
    "for i, tokens in enumerate(all_tokens) :\n",
    "    width = beam_size[i]\n",
    "    token_list = [copy.deepcopy(tokens) for _ in range(width)]\n",
    "    beam_set = [[] for _ in range(len(token_list[0]))]\n",
    "    \n",
    "    for j in range(len(tokens)) :\n",
    "        word_list = []\n",
    "        \n",
    "        if j == 0 :            \n",
    "            for t in token_list[0] :\n",
    "                word_list.append(t)\n",
    "            \n",
    "            perplexities = np.array(evaluatr.get_perplexity(word_list, batch_size = 256))\n",
    "            \n",
    "        else :\n",
    "            for m, beam in enumerate(beam_set) :\n",
    "                for t in token_list[m] :\n",
    "                    word_list.append(\" \".join(beam + [t]))\n",
    "                    \n",
    "            if len(word_list[0]) > 40 :\n",
    "                perplexities = np.array(evaluatr.get_perplexity(word_list, batch_size = 128))\n",
    "                \n",
    "            else :\n",
    "                perplexities = np.array(evaluatr.get_perplexity(word_list, batch_size = 256))\n",
    "                \n",
    "        min_indexs = perplexities.argsort()[:width]\n",
    "        token_len = len(token_list[0])\n",
    "        tmp = copy.deepcopy(beam_set)\n",
    "        beam_set = [tmp[min_index//token_len] + [token_list[min_index//token_len][min_index%token_len]] for min_index in min_indexs]\n",
    "    \n",
    "        tmp = copy.deepcopy(token_list)\n",
    "        \n",
    "        for l, min_index in enumerate(min_indexs) :\n",
    "            token_list[l] = copy.deepcopy(tmp[min_index//token_len])\n",
    "            del token_list[l][min_index%token_len]\n",
    "                \n",
    "\n",
    "    print(f\"cycle rooped\")\n",
    "        \n",
    "    best_word.append(beam_set[perplexities.argmin()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\"id\":[0,1,2,3,4,5], \"text\":[\" \".join(w) for w in best_word]})\n",
    "df_submission.iloc[0, 1] = \"reindeer mistletoe elf gingerbread family advent scrooge chimney fireplace ornament\"\n",
    "df_submission.to_csv(\"beam.csv\")\n",
    "\n",
    "os.system(\"kaggle competitions submit -c santa-2024 -f beam.csv -m .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
