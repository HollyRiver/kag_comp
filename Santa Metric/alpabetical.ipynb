{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from math import exp\n",
    "from collections import Counter\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "import heapq\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import statistics\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Callable, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc ## for memory\n",
    "import os\n",
    "import copy\n",
    "from math import exp\n",
    "from collections import Counter\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "## environment variable setting\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "# os.system(\"huggingface-cli login\")\n",
    "PAD_TOKEN_LABEL_ID = torch.nn.CrossEntropyLoss().ignore_index\n",
    "DEVICE = torch.device('cuda')\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def score(\n",
    "    solution: pd.DataFrame,\n",
    "    submission: pd.DataFrame,\n",
    "    row_id_column_name: str,\n",
    "    model_path: str = 'google/gemma-2-9b',\n",
    "    load_in_8bit: bool = False,\n",
    "    clear_mem: bool = False,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculates the mean perplexity of submitted text permutations compared to an original text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    solution : DataFrame\n",
    "        DataFrame containing the original text in a column named 'text'.\n",
    "        Includes a row ID column specified by `row_id_column_name`.\n",
    "\n",
    "    submission : DataFrame\n",
    "        DataFrame containing the permuted text in a column named 'text'.\n",
    "        Must have the same row IDs as the solution.\n",
    "        Includes a row ID column specified by `row_id_column_name`.\n",
    "\n",
    "    row_id_column_name : str\n",
    "        Name of the column containing row IDs.\n",
    "        Ensures aligned comparison between solution and submission.\n",
    "\n",
    "    model_path : str, default='/kaggle/input/gemma-2/transformers/gemma-2-9b/2'\n",
    "        Path to the serialized LLM.\n",
    "\n",
    "    load_in_8bit : bool, default=False\n",
    "        Use 8-bit quantization for the model. Requires CUDA.\n",
    "\n",
    "    clear_mem : bool, default=False\n",
    "        Clear GPU memory after scoring by clearing the CUDA cache.\n",
    "        Useful for testing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The mean perplexity score. Lower is better.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ParticipantVisibleError\n",
    "        If the submission format is invalid or submitted strings are not valid permutations.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> model_path = \"/kaggle/input/gemma-2/transformers/gemma-2-9b/2\"\n",
    "    >>> solution = pd.DataFrame({\n",
    "    ...     'id': [0, 1],\n",
    "    ...     'text': [\"this is a normal english sentence\", \"the quick brown fox jumps over the lazy dog\"]\n",
    "    ... })\n",
    "    >>> submission = pd.DataFrame({\n",
    "    ...     'id': [0, 1],\n",
    "    ...     'text': [\"sentence english normal a is this\", \"lazy the over jumps fox brown quick the dog\"]\n",
    "    ... })\n",
    "    >>> score(solution, submission, 'id', model_path=model_path, clear_mem=True) > 0\n",
    "    True\n",
    "    \"\"\"\n",
    "    # Check that each submitted string is a permutation of the solution string\n",
    "    sol_counts = solution.loc[:, 'text'].str.split().apply(Counter)\n",
    "    sub_counts = submission.loc[:, 'text'].str.split().apply(Counter)\n",
    "    invalid_mask = sol_counts != sub_counts\n",
    "    if invalid_mask.any():\n",
    "        raise ParticipantVisibleError(\n",
    "            'At least one submitted string is not a valid permutation of the solution string.'\n",
    "        )\n",
    "\n",
    "    # Calculate perplexity for the submitted strings\n",
    "    sub_strings = [\n",
    "        ' '.join(s.split()) for s in submission['text'].tolist()\n",
    "    ]  # Split and rejoin to normalize whitespace\n",
    "    scorer = PerplexityCalculator(\n",
    "        model_path=model_path,\n",
    "        load_in_8bit=load_in_8bit,\n",
    "    )  # Initialize the perplexity calculator with a pre-trained model\n",
    "    perplexities = scorer.get_perplexity(\n",
    "        sub_strings\n",
    "    )  # Calculate perplexity for each submitted string\n",
    "\n",
    "    if clear_mem:\n",
    "        # Just move on if it fails. Not essential if we have the score.\n",
    "        try:\n",
    "            scorer.clear_gpu_memory()\n",
    "        except:\n",
    "            print('GPU memory clearing failed.')\n",
    "\n",
    "    return float(np.mean(perplexities))\n",
    "\n",
    "\n",
    "class PerplexityCalculator:\n",
    "    \"\"\"\n",
    "    Calculates perplexity of text using a pre-trained language model.\n",
    "\n",
    "    Adapted from https://github.com/asahi417/lmppl/blob/main/lmppl/ppl_recurrent_lm.py\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_path : str\n",
    "        Path to the pre-trained language model\n",
    "\n",
    "    load_in_8bit : bool, default=False\n",
    "        Use 8-bit quantization for the model. Requires CUDA.\n",
    "\n",
    "    device_map : str, default=\"auto\"\n",
    "        Device mapping for the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: str,\n",
    "        load_in_8bit: bool = False,\n",
    "        device_map: str = 'auto',\n",
    "    ):\n",
    "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(model_path, padding_side = 'right')\n",
    "        # Configure model loading based on quantization setting and device availability\n",
    "        if load_in_8bit:\n",
    "            if DEVICE.type != 'cuda':\n",
    "                raise ValueError('8-bit quantization requires CUDA device')\n",
    "            quantization_config = transformers.BitsAndBytesConfig(load_in_8bit=True)\n",
    "            self.model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "                model_path,\n",
    "                quantization_config=quantization_config,\n",
    "                device_map=device_map,\n",
    "            )\n",
    "        else:\n",
    "            self.model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "                model_path,\n",
    "                torch_dtype=torch.float16 if DEVICE.type == 'cuda' else torch.float32,\n",
    "                device_map=device_map,\n",
    "            )\n",
    "\n",
    "        self.loss_fct = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "    def get_perplexity(\n",
    "            self, input_texts: Union[str, List[str]], batch_size: 32\n",
    "        ) -> Union[float, List[float]]:\n",
    "\n",
    "            single_input = isinstance(input_texts, str)\n",
    "            input_texts = [input_texts] if single_input else input_texts\n",
    "\n",
    "            loss_list = []\n",
    "\n",
    "            batches = len(input_texts)//batch_size + (len(input_texts)%batch_size != 0)\n",
    "            for j in range(batches):\n",
    "\n",
    "                a = j*batch_size\n",
    "                b = (j+1)*batch_size\n",
    "                input_batch = input_texts[a:b]\n",
    "\n",
    "                with torch.no_grad():\n",
    "\n",
    "                    # Explicitly add sequence boundary tokens to the text\n",
    "                    text_with_special = [f\"{self.tokenizer.bos_token}{text}{self.tokenizer.eos_token}\" for text in input_batch]\n",
    "\n",
    "                    # Tokenize\n",
    "                    model_inputs = self.tokenizer(\n",
    "                        text_with_special,\n",
    "                        return_tensors='pt',\n",
    "                        add_special_tokens=False,\n",
    "                        padding=True\n",
    "                    )\n",
    "\n",
    "                    if 'token_type_ids' in model_inputs:\n",
    "                        model_inputs.pop('token_type_ids')\n",
    "\n",
    "                    model_inputs = {k: v.to(DEVICE) for k, v in model_inputs.items()}\n",
    "\n",
    "                    # Get model output\n",
    "                    output = self.model(**model_inputs, use_cache=False)\n",
    "                    logits = output['logits']\n",
    "\n",
    "                    label = model_inputs['input_ids']\n",
    "                    label[label == self.tokenizer.pad_token_id] = PAD_TOKEN_LABEL_ID\n",
    "\n",
    "                    # Shift logits and labels for calculating loss\n",
    "                    shift_logits = logits[..., :-1, :].contiguous()  # Drop last prediction\n",
    "                    shift_labels = label[..., 1:].contiguous()  # Drop first input\n",
    "\n",
    "                    # Calculate token-wise loss\n",
    "                    loss = self.loss_fct(\n",
    "                        shift_logits.view(-1, shift_logits.size(-1)),\n",
    "                        shift_labels.view(-1)\n",
    "                    )\n",
    "\n",
    "                    loss = loss.view(len(logits), -1)\n",
    "                    valid_length = (shift_labels != PAD_TOKEN_LABEL_ID).sum(dim=-1)\n",
    "                    loss = torch.sum(loss, -1) / valid_length\n",
    "\n",
    "                    loss_list += loss.cpu().tolist()\n",
    "\n",
    "            ppl = [exp(i) for i in loss_list]\n",
    "\n",
    "            return ppl[0] if single_input else ppl\n",
    "\n",
    "    def clear_gpu_memory(self) -> None:\n",
    "        \"\"\"Clears GPU memory by deleting references and emptying caches.\"\"\"\n",
    "        if not torch.cuda.is_available():\n",
    "            return\n",
    "\n",
    "        # Delete model and tokenizer if they exist\n",
    "        if hasattr(self, 'model'):\n",
    "            del self.model\n",
    "        if hasattr(self, 'tokenizer'):\n",
    "            del self.tokenizer\n",
    "\n",
    "        # Run garbage collection\n",
    "        gc.collect()\n",
    "\n",
    "        # Clear CUDA cache and reset memory stats\n",
    "        with DEVICE:\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.ipc_collect()\n",
    "            torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731d2283cd474d379bf74c21671e4e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"google/gemma-2-9b\"\n",
    "scorer = PerplexityCalculator(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configuration:\n",
    "    \"\"\"\n",
    "    A class holding:\n",
    "      - stopwords (set)\n",
    "      - semi_free_words (set)\n",
    "      - config dict:\n",
    "        {\n",
    "          'letters': {\n",
    "            letter_name: {\n",
    "               'rooms': [ [occupant1, occupant2, ...], ... ]\n",
    "            },\n",
    "            ...\n",
    "          },\n",
    "          'free_pool': [some stopwords or other items]\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stopwords=None, semi_free_words=None, initial_config=None):\n",
    "        self.stopwords = set(stopwords) if stopwords else set()\n",
    "        self.semi_free_words = set(semi_free_words) if semi_free_words else set()\n",
    "\n",
    "        if initial_config:\n",
    "            self.config = initial_config\n",
    "        else:\n",
    "            self.config = {\n",
    "                \"letters\": {},\n",
    "                \"free_pool\": []\n",
    "            }\n",
    "\n",
    "    def flatten_encode(self) -> str:\n",
    "        tokens = []\n",
    "        tokens.extend(self.config['free_pool'])\n",
    "        letters_ordered = sorted(self.config['letters'])\n",
    "        max_room_count = 0\n",
    "        for lt in letters_ordered:\n",
    "            max_room_count = max(max_room_count, len(self.config['letters'][lt]['rooms']))\n",
    "\n",
    "        for room_idx in range(max_room_count):\n",
    "            for letter in letters_ordered:\n",
    "                rooms = self.config['letters'][letter]['rooms']\n",
    "                if room_idx < len(rooms):\n",
    "                    tokens.extend(rooms[room_idx])\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.flatten_encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_5_state = {\n",
    "    'letters': {\n",
    "        'a': {\n",
    "            'rooms': [\n",
    "                ['advent', 'angel'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'b': {\n",
    "            'rooms': [\n",
    "                ['bake', 'beard', 'believe', 'bow'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'c': {\n",
    "            'rooms': [\n",
    "                ['candle', 'candy', 'card', 'carol', 'cheer', 'cheer', 'chimney', 'chimney', 'chocolate', 'cookie'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'd': {\n",
    "            'rooms': [\n",
    "                ['decorations', 'doll', 'dream', 'drive'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'e': {\n",
    "            'rooms': [\n",
    "                ['eat', 'eggnog', 'elf'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'f': {\n",
    "            'rooms': [\n",
    "                ['family', 'fireplace', 'fireplace', 'fruitcake'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'g': {\n",
    "            'rooms': [\n",
    "                ['game', 'gifts', 'gingerbread', 'give', 'greeting', 'grinch'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'h': {\n",
    "            'rooms': [\n",
    "                ['hohoho', 'holiday', 'holly', 'hope'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'j': {\n",
    "            'rooms': [\n",
    "                [ 'jingle', 'joy', 'jump'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'k': {\n",
    "            'rooms': [\n",
    "                ['kaggle'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'l': {\n",
    "            'rooms': [\n",
    "                ['laugh'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'm': {\n",
    "            'rooms': [\n",
    "                ['magi', 'merry', 'milk', 'mistletoe'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'n': {\n",
    "            'rooms': [\n",
    "                ['naughty', 'nice', 'night', 'night', 'nutcracker'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'o': {\n",
    "            'rooms': [\n",
    "                ['ornament', 'ornament'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'p': {\n",
    "            'rooms': [\n",
    "                ['paper', 'peace', 'peppermint', 'poinsettia', 'polar', 'puzzle'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'r': {\n",
    "            'rooms': [\n",
    "                ['reindeer', 'relax'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        's': {\n",
    "            'rooms': [\n",
    "                ['scrooge', 'season', 'sing', 'sleep', 'sleigh', 'snowglobe', 'star', 'stocking'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        't': {\n",
    "            'rooms': [\n",
    "                ['toy'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'u': {\n",
    "            'rooms': [\n",
    "                ['unwrap'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'v': {\n",
    "            'rooms': [\n",
    "                ['visit'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'w': {\n",
    "            'rooms': [\n",
    "                ['walk', 'wish', 'wonder', 'workshop', 'workshop', 'wrapping', 'wreath'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        'y': {\n",
    "            'rooms': [\n",
    "                ['yuletide'],\n",
    "                []\n",
    "                ]\n",
    "            },\n",
    "        },\n",
    "    'free_pool': ['the', 'the', 'the', 'of', 'of', 'and', 'to', 'in', 'and', 'is', 'and', 'you', 'that', 'it', 'we', 'with', 'from', 'have', 'not', 'as' ]\n",
    "    }\n",
    "\n",
    "stopwords = ['the', 'the', 'the', 'of', 'of', 'and', 'to', 'in', 'and', 'is', 'and', 'you', 'that', 'it', 'we', 'with', 'from', 'have', 'not', 'as' ]\n",
    "\n",
    "sample5_config = Configuration(stopwords=stopwords, initial_config=sample_5_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoveRegistry:\n",
    "    \"\"\"\n",
    "    Holds a collection of moves, each with a weight (probability).\n",
    "    Each move is a function: move_func(config: Configuration) -> None\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.moves: List[Tuple[str, Callable[[Configuration], None], float]] = []\n",
    "\n",
    "    def register_move(self, name: str, func: Callable[[Configuration], None], weight: float):\n",
    "        self.moves.append((name, func, weight))\n",
    "\n",
    "    def unregister_move(self, name: str):\n",
    "        self.moves = [(n, f, w) for (n, f, w) in self.moves if n != name]\n",
    "\n",
    "    def pick_move(self) -> Callable[[Configuration], None]:\n",
    "        \"\"\"Select one move function according to the stored weights.\"\"\"\n",
    "        if not self.moves:\n",
    "            return lambda c: None\n",
    "        funcs = [m[1] for m in self.moves]\n",
    "        weights = [m[2] for m in self.moves]\n",
    "        chosen_func = random.choices(funcs, weights=weights, k=1)[0]\n",
    "        return chosen_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Moves:\n",
    "    @staticmethod\n",
    "    def move_item_between_groups(cfg: Configuration):\n",
    "        letters = list(cfg.config['letters'])\n",
    "        if not letters:\n",
    "            return\n",
    "        letter_1, letter_2 = random.sample(letters, k=2)\n",
    "        \n",
    "        rooms_1 = cfg.config['letters'][letter_1]['rooms']\n",
    "        rooms_2 = cfg.config['letters'][letter_2]['rooms']\n",
    "        non_empty_1 = [idx for idx, r in enumerate(rooms_1) if r]\n",
    "        if not non_empty_1:\n",
    "            return\n",
    "            \n",
    "        src = random.choice(non_empty_1)\n",
    "        dst = random.choice(list(range(len(rooms_2))))\n",
    "        \n",
    "        item_idx = random.randrange(len(rooms_1[src]))\n",
    "        item = rooms_1[src].pop(item_idx)\n",
    "        insert_pos = random.randint(0, len(rooms_2[dst]))\n",
    "        rooms_2[dst].insert(insert_pos, item)\n",
    "        \n",
    "    @staticmethod\n",
    "    def rotate_room_elements(cfg: Configuration):\n",
    "        letters = list(cfg.config['letters'])\n",
    "        if not letters:\n",
    "            return\n",
    "        letter = random.choice(letters)\n",
    "        rooms = cfg.config['letters'][letter]['rooms']\n",
    "        if not rooms:\n",
    "            return\n",
    "        r_idx = random.randrange(len(rooms))\n",
    "        rlist = rooms[r_idx]\n",
    "        if len(rlist) > 1:\n",
    "            first_item = rlist.pop(0)\n",
    "            rlist.append(first_item)\n",
    "\n",
    "    @staticmethod\n",
    "    def swap_elements_in_room(cfg: Configuration):\n",
    "        letters = list(cfg.config['letters'])\n",
    "        if not letters:\n",
    "            return\n",
    "        letter = random.choice(letters)\n",
    "        rooms = cfg.config['letters'][letter]['rooms']\n",
    "        swappable = [idx for idx, rlist in enumerate(rooms) if len(rlist) >= 2]\n",
    "        if not swappable:\n",
    "            return\n",
    "        chosen_room_idx = random.choice(swappable)\n",
    "        rlist = rooms[chosen_room_idx]\n",
    "        i, j = random.sample(range(len(rlist)), 2)\n",
    "        rlist[i], rlist[j] = rlist[j], rlist[i]\n",
    "\n",
    "    @staticmethod\n",
    "    def move_item_between_rooms(cfg: Configuration):\n",
    "        letters = list(cfg.config['letters'])\n",
    "        if not letters:\n",
    "            return\n",
    "        letter = random.choice(letters)\n",
    "        rooms = cfg.config['letters'][letter]['rooms']\n",
    "        if len(rooms) < 2:\n",
    "            return\n",
    "        non_empty = [idx for idx, r in enumerate(rooms) if r]\n",
    "        if not non_empty:\n",
    "            return\n",
    "        src = random.choice(non_empty)\n",
    "        targets = [i for i in range(len(rooms)) if i != src]\n",
    "        dst = random.choice(targets)\n",
    "        item_idx = random.randrange(len(rooms[src]))\n",
    "        item = rooms[src].pop(item_idx)\n",
    "        insert_pos = random.randint(0, len(rooms[dst]))\n",
    "        rooms[dst].insert(insert_pos, item)\n",
    "\n",
    "    @staticmethod\n",
    "    def move_item_to_matching_group(cfg: Configuration):\n",
    "        letters = list(cfg.config['letters'])\n",
    "        if not letters:\n",
    "            return\n",
    "        letter_1 = random.choice(letters)\n",
    "        rooms_1 = cfg.config['letters'][letter_1]['rooms']\n",
    "        non_empty_1 = [idx for idx, r in enumerate(rooms_1) if r]\n",
    "        if not non_empty_1:\n",
    "            return\n",
    "        src = random.choice(non_empty_1)\n",
    "        item_idx = random.randrange(len(rooms_1[src]))\n",
    "        item = rooms_1[src].pop(item_idx)\n",
    "        first_letter = item[0].lower()\n",
    "        if first_letter not in cfg.config['letters']:\n",
    "            return\n",
    "        rooms_2 = cfg.config['letters'][first_letter]['rooms']\n",
    "        dst = random.choice(list(range(len(rooms_2))))\n",
    "        insert_pos = random.randint(0, len(rooms_2[dst]))\n",
    "        rooms_2[dst].insert(insert_pos, item)\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def swap_items_in_free_pool(cfg: Configuration):\n",
    "        \"\"\"\n",
    "        Swap two items at random indices in the free_pool, if the free_pool has >= 2 items.\n",
    "        \"\"\"\n",
    "        pool = cfg.config['free_pool']\n",
    "        if len(pool) < 2:\n",
    "            return\n",
    "        i, j = random.sample(range(len(pool)), 2)\n",
    "        pool[i], pool[j] = pool[j], pool[i]\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def free_to_room(cfg: Configuration):\n",
    "        if not cfg.config['free_pool']:\n",
    "            return\n",
    "        item_idx = random.randrange(len(cfg.config['free_pool']))\n",
    "        item = cfg.config['free_pool'].pop(item_idx)\n",
    "\n",
    "        letters = list(cfg.config['letters'])\n",
    "        if not letters:\n",
    "            cfg.config['free_pool'].append(item)\n",
    "            return\n",
    "        letter = random.choice(letters)\n",
    "        rooms = cfg.config['letters'][letter]['rooms']\n",
    "        if not rooms:\n",
    "            cfg.config['free_pool'].append(item)\n",
    "            return\n",
    "        r_idx = random.randrange(len(rooms))\n",
    "        insert_pos = random.randint(0, len(rooms[r_idx]))\n",
    "        rooms[r_idx].insert(insert_pos, item)\n",
    "\n",
    "    @staticmethod\n",
    "    def room_to_free(cfg: Configuration):\n",
    "        stopwords = cfg.stopwords\n",
    "        letters = list(cfg.config['letters'])\n",
    "        if not letters:\n",
    "            return\n",
    "        possible_spots = []\n",
    "        for letter in letters:\n",
    "            rooms = cfg.config['letters'][letter]['rooms']\n",
    "            for i, rlist in enumerate(rooms):\n",
    "                if any((x in stopwords) for x in rlist):\n",
    "                    possible_spots.append((letter, i))\n",
    "        if not possible_spots:\n",
    "            return\n",
    "        letter, r_idx = random.choice(possible_spots)\n",
    "        rlist = cfg.config['letters'][letter]['rooms'][r_idx]\n",
    "        candidates = [idx for idx, x in enumerate(rlist) if (x in stopwords)]\n",
    "        if not candidates:\n",
    "            return\n",
    "        sw_idx = random.choice(candidates)\n",
    "        sw = rlist.pop(sw_idx)\n",
    "        insert_pos = random.randint(0, len(cfg.config['free_pool']))\n",
    "        cfg.config['free_pool'].insert(insert_pos, sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "register = MoveRegistry()\n",
    "register.register_move('rotate', Moves.rotate_room_elements, 0.2)\n",
    "register.register_move('swap', Moves.swap_elements_in_room, 0.5)\n",
    "register.register_move('move', Moves.move_item_between_rooms, 1.0)\n",
    "register.register_move('group', Moves.move_item_between_groups, 0.5)\n",
    "# register.register_move('back', Moves.move_item_to_matching_room, 0.2)\n",
    "#register.register_move('swap2',Moves.swap_items_in_free_pool, 0.2)\n",
    "#register.register_move('f2r',Moves.free_to_room, 0.2)\n",
    "#register.register_move('r2f',Moves.room_to_free, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatedAnnealing:\n",
    "    def __init__(self, start_temp, end_temp, max_iterations, cost_fn):\n",
    "        self.start_temp = start_temp\n",
    "        self.end_temp = end_temp\n",
    "        self.max_iterations = max_iterations\n",
    "        self.cost_fn = cost_fn\n",
    "        self.register = register\n",
    "\n",
    "    def _generate_neighbor(self, cfg):\n",
    "        new_cfg = copy.deepcopy(cfg)\n",
    "        move = self.register.pick_move()\n",
    "        move(new_cfg)\n",
    "        return new_cfg\n",
    "\n",
    "    def _acceptance_probability(self, diff, temperature):\n",
    "        if diff <= 0:\n",
    "            return 1.0\n",
    "        return math.exp(- diff/ temperature)\n",
    "\n",
    "    def _lower_temperature(self, temperature, iteration):\n",
    "        t1 = self.end_temp + self.start_temp/(1 + math.log(iteration+1))\n",
    "        t2 = self.start_temp + (self.end_temp - self.start_temp)*(iteration/self.max_iterations)\n",
    "        return max(t1, t2)\n",
    "\n",
    "    def _print_progress(\n",
    "        self,\n",
    "        iteration: int,\n",
    "        best_solutions: List[List[str]],\n",
    "        best_energies: List[float],\n",
    "        current_solutions: List[List[str]],\n",
    "        current_energies: List[float],\n",
    "        temperature: float,\n",
    "        start_time: float,\n",
    "        spend_minute: int\n",
    "    ) -> int:\n",
    "        current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        # Check if 60 seconds have passed since the last update\n",
    "        if elapsed_time - 60 * spend_minute > 60:\n",
    "            spend_minute += 1\n",
    "            progress = iteration / self.max_iterations * 100  # Progress as percentage\n",
    "\n",
    "            # Print progress in a structured format\n",
    "            print(\"===== Simulated Annealing Progress =====\")\n",
    "            print(f\"Time: {current_time}\")\n",
    "            print(f\"Iteration: {iteration}/{self.max_iterations} ({progress:.2f}%)\")\n",
    "            print(f\"Temperature: {temperature:.4f}\")\n",
    "            print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "            # Print best solutions and energies\n",
    "            print(\"\\nBest Solutions:\")\n",
    "            for i, solution in enumerate(best_solutions):\n",
    "                print(f\"  Solution {i+1}: {solution}\")\n",
    "            print(\"\\nBest Energies:\")\n",
    "            print(\"  \" + \", \".join(f\"{exp(energy):.4f}\" for energy in best_energies))\n",
    "\n",
    "            # Print current solutions and energies\n",
    "            print(\"\\nCurrent Solutions:\")\n",
    "            for i, solution in enumerate(current_solutions):\n",
    "                print(f\"  Solution {i+1}: {solution}\")\n",
    "            print(\"\\nCurrent Energies:\")\n",
    "            print(\"  \" + \", \".join(f\"{exp(energy):.4f}\" for energy in current_energies))\n",
    "\n",
    "            print(\"========================================\\n\")\n",
    "\n",
    "        return spend_minute\n",
    "\n",
    "    def solve_batch(self, text_list):\n",
    "        \"\"\"\n",
    "        Perform Simulated Annealing for multiple texts at once.\n",
    "        \"\"\"\n",
    "        solutions = text_list[:]\n",
    "        current_energies = self.cost_fn(solutions)\n",
    "\n",
    "        best_solutions = solutions[:]\n",
    "        best_energies = current_energies[:]\n",
    "\n",
    "        log_energies = [[] for _ in range(len(text_list))]\n",
    "        for i in range(len(text_list)):\n",
    "            log_energies[i].append(current_energies[i])\n",
    "\n",
    "        temperature = self.start_temp\n",
    "        start_time = time.time()\n",
    "        spend_minute = 0\n",
    "\n",
    "        for iteration in range(self.max_iterations):\n",
    "            # 1) Generate neighbors\n",
    "            new_solutions = [self._generate_neighbor(sol) for sol in solutions]\n",
    "\n",
    "            # 2) Calculate new energies in batch\n",
    "            new_energies = self.cost_fn(new_solutions)\n",
    "\n",
    "            # 3) Acceptance and update\n",
    "            for i in range(len(text_list)):\n",
    "\n",
    "                diff = new_energies[i] - current_energies[i]\n",
    "                ap = self._acceptance_probability(diff, temperature)\n",
    "\n",
    "                if random.random() < ap:\n",
    "                    solutions[i] = new_solutions[i]\n",
    "                    current_energies[i] = new_energies[i]\n",
    "\n",
    "                if current_energies[i] < best_energies[i]:\n",
    "                    best_solutions[i] = solutions[i]\n",
    "                    best_energies[i] = current_energies[i]\n",
    "\n",
    "            # 4) Lower temperature\n",
    "            temperature = self._lower_temperature(temperature, iteration)\n",
    "\n",
    "            # 5) Log current energies\n",
    "            for i in range(len(text_list)):\n",
    "                log_energies[i].append(current_energies[i])\n",
    "\n",
    "            # 6) Print progress (extracted into separate method)\n",
    "            spend_minute = self._print_progress(\n",
    "                iteration,\n",
    "                best_solutions,\n",
    "                best_energies,\n",
    "                solutions,\n",
    "                current_energies,\n",
    "                temperature,\n",
    "                start_time,\n",
    "                spend_minute\n",
    "            )\n",
    "\n",
    "            # 7) Early stop if temperature is below threshold\n",
    "            if temperature <= self.end_temp:\n",
    "                print(\"Reached the minimum temperature. Exiting.\")\n",
    "                break\n",
    "\n",
    "        print(f\"Execution time: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "        # Convert best solutions back to strings\n",
    "        return best_solutions, best_energies, log_energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(cfg_list: List[Configuration]) -> float:\n",
    "    all_items = [cfg.flatten_encode() for cfg in cfg_list]\n",
    "    return scorer.get_perplexity(all_items, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_params = {\n",
    "    'start_temp': 0.012,             # Initial temperature\n",
    "    'end_temp': 0.0012,          # Final temperature, decreasing linearly\n",
    "    'max_iterations': 100000,    # Number of iterations (approximately 4 hours for 100,000 iterations)\n",
    "    \"cost_fn\": compute_cost,\n",
    "}\n",
    "\n",
    "sa_optimizer = SimulatedAnnealing(**sa_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "states = [copy.deepcopy(sample5_config) for i in range(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Simulated Annealing Progress =====\n",
      "Time: 2025-01-27 21:12:50\n",
      "Iteration: 710/100000 (0.71%)\n",
      "Temperature: 0.0119\n",
      "Elapsed Time: 60.07 seconds\n",
      "\n",
      "Best Solutions:\n",
      "  Solution 1: the the the of of and to in and is and you that it we with from have not as advent angel bake beard believe bow candle candy card carol cheer cheer chimney chimney chocolate cookie decorations doll dream drive eat eggnog elf family fireplace fireplace fruitcake game gingerbread gifts give greeting grinch hohoho holiday holly hope jingle jump joy kaggle laugh magi merry milk mistletoe naughty nice night night nutcracker ornament ornament paper peace peppermint polar poinsettia puzzle reindeer relax scrooge season sing sleep sleigh snowglobe star stocking toy unwrap visit walk wish wonder workshop workshop wrapping wreath yuletide\n",
      "\n",
      "Best Energies:\n",
      "  9584554707844220.0000\n",
      "\n",
      "Current Solutions:\n",
      "  Solution 1: the the the of of and to in and is and you that it we with from have not as advent angel bake beard believe bow candle candy card carol cheer cheer chimney chimney chocolate cookie decorations doll dream drive eat eggnog elf family fireplace fireplace fruitcake game gingerbread gifts give greeting grinch hohoho holiday holly hope jingle jump joy kaggle laugh magi merry milk mistletoe naughty nice night night nutcracker ornament ornament paper peace peppermint polar poinsettia puzzle reindeer relax scrooge season sing sleep sleigh snowglobe star stocking toy unwrap visit walk wish wonder workshop workshop wrapping wreath yuletide\n",
      "\n",
      "Current Energies:\n",
      "  9584554707844220.0000\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_solutions, best_energies, log_scores \u001b[38;5;241m=\u001b[39m \u001b[43msa_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 92\u001b[0m, in \u001b[0;36mSimulatedAnnealing.solve_batch\u001b[0;34m(self, text_list)\u001b[0m\n\u001b[1;32m     89\u001b[0m new_solutions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_neighbor(sol) \u001b[38;5;28;01mfor\u001b[39;00m sol \u001b[38;5;129;01min\u001b[39;00m solutions]\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# 2) Calculate new energies in batch\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m new_energies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_solutions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# 3) Acceptance and update\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(text_list)):\n",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m, in \u001b[0;36mcompute_cost\u001b[0;34m(cfg_list)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_cost\u001b[39m(cfg_list: List[Configuration]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m      2\u001b[0m     all_items \u001b[38;5;241m=\u001b[39m [cfg\u001b[38;5;241m.\u001b[39mflatten_encode() \u001b[38;5;28;01mfor\u001b[39;00m cfg \u001b[38;5;129;01min\u001b[39;00m cfg_list]\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_perplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 218\u001b[0m, in \u001b[0;36mPerplexityCalculator.get_perplexity\u001b[0;34m(self, input_texts, batch_size)\u001b[0m\n\u001b[1;32m    215\u001b[0m         valid_length \u001b[38;5;241m=\u001b[39m (shift_labels \u001b[38;5;241m!=\u001b[39m PAD_TOKEN_LABEL_ID)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    216\u001b[0m         loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(loss, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m valid_length\n\u001b[0;32m--> 218\u001b[0m         loss_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    220\u001b[0m ppl \u001b[38;5;241m=\u001b[39m [exp(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m loss_list]\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ppl[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single_input \u001b[38;5;28;01melse\u001b[39;00m ppl\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_solutions, best_energies, log_scores = sa_optimizer.solve_batch(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for score in log_scores:\n",
    "    plt.plot(score)\n",
    "plt.xlabel('sa_iteration')\n",
    "plt.ylabel('score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
